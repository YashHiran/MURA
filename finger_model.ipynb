{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormality Detection in Musculoskeletal Radiographs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XR_FINGER Study Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.densenet import DenseNet169, DenseNet121, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, image\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a csv file containing path to image & csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_metadata_csv(category,study_types):\n",
    "    \"\"\"\n",
    "    This function creates a csv file containing the path of images, label.\n",
    "    \"\"\"\n",
    "    image_data = {}\n",
    "    study_label = {'positive': 1, 'negative': 0}\n",
    "    #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
    "    #study_types = ['XR_ELBOW']\n",
    "    i = 0\n",
    "    image_data[category] = pd.DataFrame(columns=['Path','Count', 'Label'])\n",
    "    for study_type in study_types: # Iterate throught every study types\n",
    "        DATA_DIR = 'data/MURA-v1.1/%s/%s/' % (category, study_type)\n",
    "        patients = list(os.walk(DATA_DIR))[0][1]  # list of patient folder names\n",
    "        for patient in tqdm(patients):  # for each patient folder\n",
    "            for study in os.listdir(DATA_DIR + patient):  # for each study in that patient folder\n",
    "                if(study != '.DS_Store'):\n",
    "                    label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
    "                    path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
    "                    for j in range(len(list(listdir_nohidden(path)))):\n",
    "                        image_path = path + 'image%s.png' % (j + 1)\n",
    "                        image_data[category].loc[i] = [image_path,1, label]  # add new row\n",
    "                        i += 1\n",
    "    image_data[category].to_csv(category+\"_image_data.csv\",index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New function create image array by study level\n",
    "def getImagesInArrayNew(train_dataframe):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, data in tqdm(train_dataframe.iterrows()):\n",
    "        img = cv2.imread(data['Path'])\n",
    "#         #random rotation\n",
    "#         angle = random.randint(-30,30)\n",
    "#         M = cv2.getRotationMatrix2D((img_width/2,img_height/2),angle,1)\n",
    "#         img = cv2.warpAffine(img,M,(img_width,img_height))\n",
    "        #resize\n",
    "        img = cv2.resize(img,(img_width,img_height))    \n",
    "        img = img[...,::-1].astype(np.float32)\n",
    "        images.append(img)\n",
    "        labels.append(data['Label'])\n",
    "    images = np.asarray(images).astype('float32') \n",
    "    #normalization\n",
    "    mean = np.mean(images[:, :, :])\n",
    "    std = np.std(images[:, :, :])\n",
    "    images[:, :, :] = (images[:, :, :] - mean) / std\n",
    "    labels = np.asarray(labels)\n",
    "    return {'images': images, 'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Variables intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "#Keras ImageDataGenerator to load, transform the images of the dataset\n",
    "BASE_DATA_DIR = 'data/'\n",
    "IMG_DATA_DIR = 'MURA-v1.1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XR_ELBOW ImageDataGenertors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1865/1865 [00:13<00:00, 133.99it/s]\n",
      "100%|██████████| 166/166 [00:01<00:00, 148.46it/s]\n",
      "461it [00:01, 271.51it/s]\n",
      "5106it [00:18, 269.46it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'train/XR_FINGER'\n",
    "valid_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'valid/XR_FINGER'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    "\n",
    ")\n",
    "\n",
    "study_types = ['XR_FINGER']\n",
    "\n",
    "create_images_metadata_csv('train',study_types)\n",
    "create_images_metadata_csv('valid',study_types)\n",
    "\n",
    "valid_image_df = pd.read_csv('valid_image_data.csv', names=['Path','Count', 'Label'])\n",
    "train_image_df = pd.read_csv('train_image_data.csv', names=['Path', 'Count','Label'])\n",
    "\n",
    "dd={}\n",
    "\n",
    "dd['train'] = train_image_df\n",
    "dd['valid'] = valid_image_df\n",
    "\n",
    "valid_dict = getImagesInArrayNew(valid_image_df)\n",
    "train_dict = getImagesInArrayNew(train_image_df)\n",
    "\n",
    "train_datagen.fit(train_dict['images'],augment=True)\n",
    "test_datagen.fit(valid_dict['images'],augment=True)\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x=valid_dict['images'],\n",
    "    y=valid_dict['labels'],\n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=train_dict['images'],\n",
    "    y=train_dict['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638\n"
     ]
    }
   ],
   "source": [
    "#model parameters for training\n",
    "#K.set_learning_phase(1)\n",
    "nb_train_samples = len(train_dict['images'])\n",
    "nb_validation_samples = len(valid_dict['images'])\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "print(steps_per_epoch)\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = DenseNet169(input_shape=(None, None,3),\n",
    "                             weights='imagenet',\n",
    "                             include_top=False,\n",
    "                             pooling='avg')\n",
    "#     i = 0\n",
    "#     total_layers = len(base_model.layers)\n",
    "#     for layer in base_model.layers:\n",
    "#         if(i <= total_layers//2):\n",
    "#             layer.trainable = False\n",
    "#             i = i+1\n",
    "\n",
    "    x = base_model.output\n",
    "    predictions = Dense(n_classes,activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['acc', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks for early stopping incase of reduced learning rate, loss unimprovement\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=0.0001)\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "638/638 [==============================] - 413s 647ms/step - loss: 0.5846 - acc: 0.6858 - mean_squared_error: 0.1984 - val_loss: 0.7364 - val_acc: 0.6140 - val_mean_squared_error: 0.2324\n",
      "Epoch 2/10\n",
      "638/638 [==============================] - 359s 562ms/step - loss: 0.5443 - acc: 0.7151 - mean_squared_error: 0.1833 - val_loss: 0.7983 - val_acc: 0.5263 - val_mean_squared_error: 0.2928\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 3/10\n",
      "638/638 [==============================] - 357s 560ms/step - loss: 0.4824 - acc: 0.7617 - mean_squared_error: 0.1590 - val_loss: 0.5056 - val_acc: 0.7719 - val_mean_squared_error: 0.1696\n",
      "Epoch 4/10\n",
      "638/638 [==============================] - 357s 560ms/step - loss: 0.4579 - acc: 0.7773 - mean_squared_error: 0.1493 - val_loss: 0.5936 - val_acc: 0.7018 - val_mean_squared_error: 0.2033\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 5/10\n",
      "638/638 [==============================] - 358s 561ms/step - loss: 0.4337 - acc: 0.7992 - mean_squared_error: 0.1398 - val_loss: 0.6060 - val_acc: 0.7544 - val_mean_squared_error: 0.1956\n",
      "Epoch 6/10\n",
      "638/638 [==============================] - 358s 561ms/step - loss: 0.4179 - acc: 0.8099 - mean_squared_error: 0.1335 - val_loss: 0.5128 - val_acc: 0.7368 - val_mean_squared_error: 0.1717\n",
      "Epoch 7/10\n",
      "638/638 [==============================] - 357s 560ms/step - loss: 0.3940 - acc: 0.8223 - mean_squared_error: 0.1249 - val_loss: 0.5659 - val_acc: 0.7368 - val_mean_squared_error: 0.1895\n",
      "Epoch 8/10\n",
      "638/638 [==============================] - 358s 561ms/step - loss: 0.3737 - acc: 0.8368 - mean_squared_error: 0.1172 - val_loss: 0.8138 - val_acc: 0.6316 - val_mean_squared_error: 0.2559\n",
      "Epoch 9/10\n",
      "638/638 [==============================] - 358s 561ms/step - loss: 0.3455 - acc: 0.8525 - mean_squared_error: 0.1072 - val_loss: 0.4797 - val_acc: 0.8070 - val_mean_squared_error: 0.1529\n",
      "Epoch 10/10\n",
      "638/638 [==============================] - 357s 560ms/step - loss: 0.3262 - acc: 0.8622 - mean_squared_error: 0.1005 - val_loss: 0.5555 - val_acc: 0.7895 - val_mean_squared_error: 0.1637\n"
     ]
    }
   ],
   "source": [
    "#train the module\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    workers=0,\n",
    "    use_multiprocessing=False,  \n",
    "    steps_per_epoch = nb_train_samples//batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples //batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"densenet_mura_rs_v3_xr_finger.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7809110629067245"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we evaluate the trained model with the validation dataset and make a prediction. \n",
    "#The class predicted will be the class with maximum value for each image.\n",
    "ev = model.evaluate_generator(validation_generator, steps=nb_validation_samples,  workers=0, use_multiprocessing=False)\n",
    "ev[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
