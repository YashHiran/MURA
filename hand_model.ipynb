{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormality Detection in Musculoskeletal Radiographs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XR_HAND Study Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.densenet import DenseNet169, DenseNet121, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, image\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a csv file containing path to image & csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_metadata_csv(category,study_types):\n",
    "    \"\"\"\n",
    "    This function creates a csv file containing the path of images, label.\n",
    "    \"\"\"\n",
    "    image_data = {}\n",
    "    study_label = {'positive': 1, 'negative': 0}\n",
    "    #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
    "    #study_types = ['XR_ELBOW']\n",
    "    i = 0\n",
    "    image_data[category] = pd.DataFrame(columns=['Path','Count', 'Label'])\n",
    "    for study_type in study_types: # Iterate throught every study types\n",
    "        DATA_DIR = 'data/MURA-v1.1/%s/%s/' % (category, study_type)\n",
    "        patients = list(os.walk(DATA_DIR))[0][1]  # list of patient folder names\n",
    "        for patient in tqdm(patients):  # for each patient folder\n",
    "            for study in os.listdir(DATA_DIR + patient):  # for each study in that patient folder\n",
    "                if(study != '.DS_Store'):\n",
    "                    label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
    "                    path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
    "                    for j in range(len(list(listdir_nohidden(path)))):\n",
    "                        image_path = path + 'image%s.png' % (j + 1)\n",
    "                        image_data[category].loc[i] = [image_path,1, label]  # add new row\n",
    "                        i += 1\n",
    "    image_data[category].to_csv(category+\"_image_data.csv\",index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New function create image array by study level\n",
    "def getImagesInArrayNew(train_dataframe):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, data in tqdm(train_dataframe.iterrows()):\n",
    "        img = cv2.imread(data['Path'])\n",
    "#         #random rotation\n",
    "#         angle = random.randint(-30,30)\n",
    "#         M = cv2.getRotationMatrix2D((img_width/2,img_height/2),angle,1)\n",
    "#         img = cv2.warpAffine(img,M,(img_width,img_height))\n",
    "        #resize\n",
    "        img = cv2.resize(img,(img_width,img_height))    \n",
    "        img = img[...,::-1].astype(np.float32)\n",
    "        images.append(img)\n",
    "        labels.append(data['Label'])\n",
    "    images = np.asarray(images).astype('float32') \n",
    "    #normalization\n",
    "    mean = np.mean(images[:, :, :])\n",
    "    std = np.std(images[:, :, :])\n",
    "    images[:, :, :] = (images[:, :, :] - mean) / std\n",
    "    labels = np.asarray(labels)\n",
    "    return {'images': images, 'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Variables intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "#Keras ImageDataGenerator to load, transform the images of the dataset\n",
    "BASE_DATA_DIR = 'data/'\n",
    "IMG_DATA_DIR = 'MURA-v1.1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XR_HAND ImageDataGenertors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1945/1945 [00:14<00:00, 131.56it/s]\n",
      "100%|██████████| 159/159 [00:01<00:00, 146.77it/s]\n",
      "460it [00:03, 118.54it/s]\n",
      "5543it [00:43, 127.12it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'train/XR_HAND'\n",
    "valid_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'valid/XR_HAND'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    "\n",
    ")\n",
    "\n",
    "study_types = ['XR_HAND']\n",
    "\n",
    "create_images_metadata_csv('train',study_types)\n",
    "create_images_metadata_csv('valid',study_types)\n",
    "\n",
    "valid_image_df = pd.read_csv('valid_image_data.csv', names=['Path','Count', 'Label'])\n",
    "train_image_df = pd.read_csv('train_image_data.csv', names=['Path', 'Count','Label'])\n",
    "\n",
    "dd={}\n",
    "\n",
    "dd['train'] = train_image_df\n",
    "dd['valid'] = valid_image_df\n",
    "\n",
    "valid_dict = getImagesInArrayNew(valid_image_df)\n",
    "train_dict = getImagesInArrayNew(train_image_df)\n",
    "\n",
    "train_datagen.fit(train_dict['images'],augment=True)\n",
    "test_datagen.fit(valid_dict['images'],augment=True)\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x=valid_dict['images'],\n",
    "    y=valid_dict['labels'],\n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=train_dict['images'],\n",
    "    y=train_dict['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n"
     ]
    }
   ],
   "source": [
    "#model parameters for training\n",
    "#K.set_learning_phase(1)\n",
    "nb_train_samples = len(train_dict['images'])\n",
    "nb_validation_samples = len(valid_dict['images'])\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "print(steps_per_epoch)\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = DenseNet169(input_shape=(None, None,3),\n",
    "                             weights='imagenet',\n",
    "                             include_top=False,\n",
    "                             pooling='avg')\n",
    "#     i = 0\n",
    "#     total_layers = len(base_model.layers)\n",
    "#     for layer in base_model.layers:\n",
    "#         if(i <= total_layers//2):\n",
    "#             layer.trainable = True\n",
    "#             i = i+1\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "#     x = Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "    predictions = Dense(n_classes,activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['acc', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks for early stopping incase of reduced learning rate, loss unimprovement\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=0.0001)\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "692/692 [==============================] - 446s 645ms/step - loss: 43.2305 - acc: 0.7307 - mean_squared_error: 0.2052 - val_loss: 2.8462 - val_acc: 0.6140 - val_mean_squared_error: 0.2410\n",
      "Epoch 2/10\n",
      "692/692 [==============================] - 392s 566ms/step - loss: 2.8506 - acc: 0.7308 - mean_squared_error: 0.1978 - val_loss: 3.1675 - val_acc: 0.4561 - val_mean_squared_error: 0.3109\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 3/10\n",
      "692/692 [==============================] - 388s 560ms/step - loss: 0.8541 - acc: 0.7347 - mean_squared_error: 0.1954 - val_loss: 0.9676 - val_acc: 0.5789 - val_mean_squared_error: 0.2634\n",
      "Epoch 4/10\n",
      "692/692 [==============================] - 388s 560ms/step - loss: 0.8328 - acc: 0.7308 - mean_squared_error: 0.1970 - val_loss: 0.8954 - val_acc: 0.6667 - val_mean_squared_error: 0.2248\n",
      "Epoch 5/10\n",
      "692/692 [==============================] - 388s 560ms/step - loss: 0.8345 - acc: 0.7321 - mean_squared_error: 0.1964 - val_loss: 0.9425 - val_acc: 0.6140 - val_mean_squared_error: 0.2482\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 6/10\n",
      "692/692 [==============================] - 389s 562ms/step - loss: 0.8341 - acc: 0.7337 - mean_squared_error: 0.1957 - val_loss: 0.9583 - val_acc: 0.5965 - val_mean_squared_error: 0.2568\n",
      "Epoch 7/10\n",
      "692/692 [==============================] - 388s 560ms/step - loss: 0.8360 - acc: 0.7315 - mean_squared_error: 0.1966 - val_loss: 0.9955 - val_acc: 0.5614 - val_mean_squared_error: 0.2717\n",
      "Epoch 8/10\n",
      "692/692 [==============================] - 388s 560ms/step - loss: 0.8348 - acc: 0.7323 - mean_squared_error: 0.1963 - val_loss: 0.9437 - val_acc: 0.6140 - val_mean_squared_error: 0.2479\n",
      "Epoch 9/10\n",
      "692/692 [==============================] - 388s 560ms/step - loss: 0.8348 - acc: 0.7316 - mean_squared_error: 0.1966 - val_loss: 0.9275 - val_acc: 0.6316 - val_mean_squared_error: 0.2403\n",
      "Epoch 10/10\n",
      "692/692 [==============================] - 388s 561ms/step - loss: 0.8322 - acc: 0.7335 - mean_squared_error: 0.1957 - val_loss: 0.9152 - val_acc: 0.6491 - val_mean_squared_error: 0.2338\n"
     ]
    }
   ],
   "source": [
    "#train the module\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    workers=0,\n",
    "    use_multiprocessing=False,  \n",
    "    steps_per_epoch = nb_train_samples//batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples //batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"densenet_mura_rs_v3_xr_hand.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5695652173913044"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we evaluate the trained model with the validation dataset and make a prediction. \n",
    "#The class predicted will be the class with maximum value for each image.\n",
    "ev = model.evaluate_generator(validation_generator, steps=nb_validation_samples,  workers=0, use_multiprocessing=False)\n",
    "ev[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
