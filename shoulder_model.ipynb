{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormality Detection in Musculoskeletal Radiographs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XR_SHOULDER Study Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.densenet import DenseNet169, DenseNet121, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, image\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a csv file containing path to image & csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_metadata_csv(category,study_types):\n",
    "    \"\"\"\n",
    "    This function creates a csv file containing the path of images, label.\n",
    "    \"\"\"\n",
    "    image_data = {}\n",
    "    study_label = {'positive': 1, 'negative': 0}\n",
    "    #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
    "    #study_types = ['XR_ELBOW']\n",
    "    i = 0\n",
    "    image_data[category] = pd.DataFrame(columns=['Path','Count', 'Label'])\n",
    "    for study_type in study_types: # Iterate throught every study types\n",
    "        DATA_DIR = 'data/MURA-v1.1/%s/%s/' % (category, study_type)\n",
    "        patients = list(os.walk(DATA_DIR))[0][1]  # list of patient folder names\n",
    "        for patient in tqdm(patients):  # for each patient folder\n",
    "            for study in os.listdir(DATA_DIR + patient):  # for each study in that patient folder\n",
    "                if(study != '.DS_Store'):\n",
    "                    label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
    "                    path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
    "                    for j in range(len(list(listdir_nohidden(path)))):\n",
    "                        image_path = path + 'image%s.png' % (j + 1)\n",
    "                        image_data[category].loc[i] = [image_path,1, label]  # add new row\n",
    "                        i += 1\n",
    "    image_data[category].to_csv(category+\"_image_data.csv\",index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New function create image array by study level\n",
    "def getImagesInArrayNew(train_dataframe):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, data in tqdm(train_dataframe.iterrows()):\n",
    "        img = cv2.imread(data['Path'])\n",
    "#         #random rotation\n",
    "#         angle = random.randint(-30,30)\n",
    "#         M = cv2.getRotationMatrix2D((img_width/2,img_height/2),angle,1)\n",
    "#         img = cv2.warpAffine(img,M,(img_width,img_height))\n",
    "        #resize\n",
    "        img = cv2.resize(img,(img_width,img_height))    \n",
    "        img = img[...,::-1].astype(np.float32)\n",
    "        images.append(img)\n",
    "        labels.append(data['Label'])\n",
    "    images = np.asarray(images).astype('float32') \n",
    "    #normalization\n",
    "    mean = np.mean(images[:, :, :])\n",
    "    std = np.std(images[:, :, :])\n",
    "    images[:, :, :] = (images[:, :, :] - mean) / std\n",
    "    labels = np.asarray(labels)\n",
    "    return {'images': images, 'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Variables intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "#Keras ImageDataGenerator to load, transform the images of the dataset\n",
    "BASE_DATA_DIR = 'data/'\n",
    "IMG_DATA_DIR = 'MURA-v1.1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XR_SHOULDER ImageDataGenertors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2694/2694 [00:23<00:00, 116.82it/s]\n",
      "100%|██████████| 173/173 [00:01<00:00, 132.19it/s]\n",
      "563it [00:02, 243.52it/s]\n",
      "8379it [00:34, 243.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'train/XR_SHOULDER'\n",
    "valid_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'valid/XR_SHOULDER'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    "\n",
    ")\n",
    "\n",
    "study_types = ['XR_SHOULDER']\n",
    "\n",
    "create_images_metadata_csv('train',study_types)\n",
    "create_images_metadata_csv('valid',study_types)\n",
    "\n",
    "valid_image_df = pd.read_csv('valid_image_data.csv', names=['Path','Count', 'Label'])\n",
    "train_image_df = pd.read_csv('train_image_data.csv', names=['Path', 'Count','Label'])\n",
    "\n",
    "dd={}\n",
    "\n",
    "dd['train'] = train_image_df\n",
    "dd['valid'] = valid_image_df\n",
    "\n",
    "valid_dict = getImagesInArrayNew(valid_image_df)\n",
    "train_dict = getImagesInArrayNew(train_image_df)\n",
    "\n",
    "train_datagen.fit(train_dict['images'],augment=True)\n",
    "test_datagen.fit(valid_dict['images'],augment=True)\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x=valid_dict['images'],\n",
    "    y=valid_dict['labels'],\n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=train_dict['images'],\n",
    "    y=train_dict['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047\n"
     ]
    }
   ],
   "source": [
    "#model parameters for training\n",
    "#K.set_learning_phase(1)\n",
    "nb_train_samples = len(train_dict['images'])\n",
    "nb_validation_samples = len(valid_dict['images'])\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "print(steps_per_epoch)\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = DenseNet169(input_shape=(None, None,3),\n",
    "                             weights='imagenet',\n",
    "                             include_top=False,\n",
    "                             pooling='avg')\n",
    "#     i = 0\n",
    "#     total_layers = len(base_model.layers)\n",
    "#     for layer in base_model.layers:\n",
    "#         if(i <= total_layers//2):\n",
    "#             layer.trainable = True\n",
    "#             i = i+1\n",
    "\n",
    "    x = base_model.output\n",
    "\n",
    "    predictions = Dense(n_classes,activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['acc', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks for early stopping incase of reduced learning rate, loss unimprovement\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=0.0001)\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1047/1047 [==============================] - 618s 590ms/step - loss: 0.6185 - acc: 0.6674 - mean_squared_error: 0.2131 - val_loss: 1.5468 - val_acc: 0.5714 - val_mean_squared_error: 0.3115\n",
      "Epoch 2/10\n",
      "1047/1047 [==============================] - 573s 548ms/step - loss: 0.5604 - acc: 0.7209 - mean_squared_error: 0.1883 - val_loss: 0.7256 - val_acc: 0.6571 - val_mean_squared_error: 0.2367\n",
      "Epoch 3/10\n",
      "1047/1047 [==============================] - 573s 548ms/step - loss: 0.5270 - acc: 0.7461 - mean_squared_error: 0.1749 - val_loss: 0.5388 - val_acc: 0.7143 - val_mean_squared_error: 0.1841\n",
      "Epoch 4/10\n",
      "1047/1047 [==============================] - 573s 547ms/step - loss: 0.5085 - acc: 0.7584 - mean_squared_error: 0.1676 - val_loss: 0.5978 - val_acc: 0.7857 - val_mean_squared_error: 0.1931\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/10\n",
      "1047/1047 [==============================] - 570s 545ms/step - loss: 0.4455 - acc: 0.7948 - mean_squared_error: 0.1439 - val_loss: 0.4550 - val_acc: 0.8143 - val_mean_squared_error: 0.1494\n",
      "Epoch 6/10\n",
      "1047/1047 [==============================] - 571s 545ms/step - loss: 0.4220 - acc: 0.8120 - mean_squared_error: 0.1348 - val_loss: 0.4564 - val_acc: 0.7571 - val_mean_squared_error: 0.1494\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 7/10\n",
      "1047/1047 [==============================] - 570s 545ms/step - loss: 0.4055 - acc: 0.8202 - mean_squared_error: 0.1291 - val_loss: 0.4924 - val_acc: 0.7571 - val_mean_squared_error: 0.1655\n",
      "Epoch 8/10\n",
      "1047/1047 [==============================] - 570s 545ms/step - loss: 0.3887 - acc: 0.8292 - mean_squared_error: 0.1227 - val_loss: 0.5686 - val_acc: 0.7714 - val_mean_squared_error: 0.1784\n",
      "Epoch 9/10\n",
      "1047/1047 [==============================] - 570s 544ms/step - loss: 0.3673 - acc: 0.8399 - mean_squared_error: 0.1156 - val_loss: 0.3640 - val_acc: 0.8571 - val_mean_squared_error: 0.1113\n",
      "Epoch 10/10\n",
      "1047/1047 [==============================] - 570s 544ms/step - loss: 0.3468 - acc: 0.8517 - mean_squared_error: 0.1079 - val_loss: 0.6474 - val_acc: 0.6857 - val_mean_squared_error: 0.2044\n"
     ]
    }
   ],
   "source": [
    "#train the module\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    workers=0,\n",
    "    use_multiprocessing=False,  \n",
    "    steps_per_epoch = nb_train_samples//batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples //batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"densenet_mura_rs_v3_xr_shoulder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.704225352112676"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we evaluate the trained model with the validation dataset and make a prediction. \n",
    "#The class predicted will be the class with maximum value for each image.\n",
    "ev = model.evaluate_generator(validation_generator, steps=(nb_validation_samples //batch_size)+1,  workers=0, use_multiprocessing=False)\n",
    "ev[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
