{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormality Detection in Musculoskeletal Radiographs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XR_ELBOW Study Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.densenet import DenseNet169, DenseNet121, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, image\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a csv file containing path to image & csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_metadata_csv(category,study_types):\n",
    "    \"\"\"\n",
    "    This function creates a csv file containing the path of images, label.\n",
    "    \"\"\"\n",
    "    image_data = {}\n",
    "    study_label = {'positive': 1, 'negative': 0}\n",
    "    #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
    "    #study_types = ['XR_ELBOW']\n",
    "    i = 0\n",
    "    image_data[category] = pd.DataFrame(columns=['Path','Count', 'Label'])\n",
    "    for study_type in study_types: # Iterate throught every study types\n",
    "        DATA_DIR = 'data/MURA-v1.1/%s/%s/' % (category, study_type)\n",
    "        patients = list(os.walk(DATA_DIR))[0][1]  # list of patient folder names\n",
    "        for patient in tqdm(patients):  # for each patient folder\n",
    "            for study in os.listdir(DATA_DIR + patient):  # for each study in that patient folder\n",
    "                if(study != '.DS_Store'):\n",
    "                    label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
    "                    path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
    "                    for j in range(len(list(listdir_nohidden(path)))):\n",
    "                        image_path = path + 'image%s.png' % (j + 1)\n",
    "                        image_data[category].loc[i] = [image_path,1, label]  # add new row\n",
    "                        i += 1\n",
    "    image_data[category].to_csv(category+\"_image_data.csv\",index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New function create image array by study level\n",
    "def getImagesInArrayNew(train_dataframe):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, data in tqdm(train_dataframe.iterrows()):\n",
    "        img = cv2.imread(data['Path'])\n",
    "#         #random rotation\n",
    "#         angle = random.randint(-30,30)\n",
    "#         M = cv2.getRotationMatrix2D((img_width/2,img_height/2),angle,1)\n",
    "#         img = cv2.warpAffine(img,M,(img_width,img_height))\n",
    "        #resize\n",
    "        img = cv2.resize(img,(img_width,img_height))    \n",
    "        img = img[...,::-1].astype(np.float32)\n",
    "        images.append(img)\n",
    "        labels.append(data['Label'])\n",
    "    images = np.asarray(images).astype('float32') \n",
    "    #normalization\n",
    "    mean = np.mean(images[:, :, :])\n",
    "    std = np.std(images[:, :, :])\n",
    "    images[:, :, :] = (images[:, :, :] - mean) / std\n",
    "    labels = np.asarray(labels)\n",
    "    return {'images': images, 'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Variables intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "#Keras ImageDataGenerator to load, transform the images of the dataset\n",
    "BASE_DATA_DIR = 'data/'\n",
    "IMG_DATA_DIR = 'MURA-v1.1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XR_ELBOW ImageDataGenertors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1711/1711 [00:12<00:00, 117.14it/s]\n",
      "100%|██████████| 152/152 [00:01<00:00, 139.27it/s]\n",
      "465it [00:01, 248.65it/s]\n",
      "4931it [00:19, 247.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'train/XR_ELBOW'\n",
    "valid_data_dir = BASE_DATA_DIR + IMG_DATA_DIR + 'valid/XR_ELBOW'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True\n",
    "\n",
    ")\n",
    "\n",
    "study_types = ['XR_ELBOW']\n",
    "\n",
    "create_images_metadata_csv('train',study_types)\n",
    "create_images_metadata_csv('valid',study_types)\n",
    "\n",
    "valid_image_df = pd.read_csv('valid_image_data.csv', names=['Path','Count', 'Label'])\n",
    "train_image_df = pd.read_csv('train_image_data.csv', names=['Path', 'Count','Label'])\n",
    "\n",
    "dd={}\n",
    "\n",
    "dd['train'] = train_image_df\n",
    "dd['valid'] = valid_image_df\n",
    "\n",
    "valid_dict = getImagesInArrayNew(valid_image_df)\n",
    "train_dict = getImagesInArrayNew(train_image_df)\n",
    "\n",
    "train_datagen.fit(train_dict['images'],augment=True)\n",
    "test_datagen.fit(valid_dict['images'],augment=True)\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x=valid_dict['images'],\n",
    "    y=valid_dict['labels'],\n",
    "    batch_size = 1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=train_dict['images'],\n",
    "    y=train_dict['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n"
     ]
    }
   ],
   "source": [
    "#model parameters for training\n",
    "#K.set_learning_phase(1)\n",
    "nb_train_samples = len(train_dict['images'])\n",
    "nb_validation_samples = len(valid_dict['images'])\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "print(steps_per_epoch)\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = DenseNet169(input_shape=(None, None,3),\n",
    "                             weights='imagenet',\n",
    "                             include_top=False,\n",
    "                             pooling='avg')\n",
    "#     i = 0\n",
    "#     total_layers = len(base_model.layers)\n",
    "#     for layer in base_model.layers:\n",
    "#         if(i <= total_layers//2):\n",
    "#             layer.trainable = True\n",
    "#             i = i+1\n",
    "\n",
    "    x = base_model.output\n",
    "    predictions = Dense(n_classes,activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['acc', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks for early stopping incase of reduced learning rate, loss unimprovement\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=0.0001)\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "616/616 [==============================] - 427s 694ms/step - loss: 0.5342 - acc: 0.7495 - mean_squared_error: 0.1763 - val_loss: 0.7980 - val_acc: 0.6724 - val_mean_squared_error: 0.2562\n",
      "Epoch 2/10\n",
      "616/616 [==============================] - 342s 555ms/step - loss: 0.4745 - acc: 0.7881 - mean_squared_error: 0.1533 - val_loss: 0.4393 - val_acc: 0.8103 - val_mean_squared_error: 0.1436\n",
      "Epoch 3/10\n",
      "616/616 [==============================] - 342s 555ms/step - loss: 0.4422 - acc: 0.8082 - mean_squared_error: 0.1406 - val_loss: 0.5473 - val_acc: 0.7241 - val_mean_squared_error: 0.1812\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 4/10\n",
      "616/616 [==============================] - 342s 556ms/step - loss: 0.3825 - acc: 0.8407 - mean_squared_error: 0.1191 - val_loss: 0.2634 - val_acc: 0.9138 - val_mean_squared_error: 0.0767\n",
      "Epoch 5/10\n",
      "616/616 [==============================] - 342s 556ms/step - loss: 0.3546 - acc: 0.8545 - mean_squared_error: 0.1094 - val_loss: 0.4644 - val_acc: 0.8103 - val_mean_squared_error: 0.1434\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 6/10\n",
      "616/616 [==============================] - 342s 555ms/step - loss: 0.3355 - acc: 0.8617 - mean_squared_error: 0.1030 - val_loss: 0.3857 - val_acc: 0.8276 - val_mean_squared_error: 0.1169\n",
      "Epoch 7/10\n",
      "616/616 [==============================] - 342s 555ms/step - loss: 0.3176 - acc: 0.8677 - mean_squared_error: 0.0972 - val_loss: 0.3228 - val_acc: 0.8793 - val_mean_squared_error: 0.0981\n",
      "Epoch 8/10\n",
      "616/616 [==============================] - 343s 556ms/step - loss: 0.2968 - acc: 0.8774 - mean_squared_error: 0.0906 - val_loss: 0.5003 - val_acc: 0.7931 - val_mean_squared_error: 0.1479\n",
      "Epoch 9/10\n",
      "616/616 [==============================] - 342s 556ms/step - loss: 0.2733 - acc: 0.8873 - mean_squared_error: 0.0826 - val_loss: 0.5154 - val_acc: 0.7414 - val_mean_squared_error: 0.1677\n",
      "Epoch 10/10\n",
      "616/616 [==============================] - 343s 557ms/step - loss: 0.2535 - acc: 0.8978 - mean_squared_error: 0.0767 - val_loss: 0.2753 - val_acc: 0.8621 - val_mean_squared_error: 0.0835\n"
     ]
    }
   ],
   "source": [
    "#train the module\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    workers=0,\n",
    "    use_multiprocessing=False,  \n",
    "    steps_per_epoch = nb_train_samples//batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples //batch_size,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"densenet_mura_rs_v3_xr_elbow.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864516129032258"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we evaluate the trained model with the validation dataset and make a prediction. \n",
    "#The class predicted will be the class with maximum value for each image.\n",
    "ev = model.evaluate_generator(validation_generator, steps=nb_validation_samples,  workers=0, use_multiprocessing=False)\n",
    "ev[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict_generator(validation_generator, steps=1, batch_size=1, use_multiprocessing=False, max_queue_size=25, verbose=1)\n",
    "validation_generator.reset()\n",
    "#pred = model.predict_generator(validation_generator,steps=nb_validation_samples)\n",
    "pred_batch = model.predict_on_batch(valid_dict['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for p in pred_batch:\n",
    "    if(p > 0.5):\n",
    "        predictions+=[1]\n",
    "    else:\n",
    "        predictions+=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.sum(np.not_equal(predictions, valid_dict['labels'])) / valid_dict['labels'].shape[0]  \n",
    "pred = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15268817204301074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
